{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymol\n",
    "from pymol import cmd,stored\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "import MDAnalysis as mda\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import matplotlib.cm as cm\n",
    "import unicodedata\n",
    "from scipy.cluster.vq import kmeans2\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set paths\n",
    "This section takes .mol2 files from working directory (HOME) of your project and generates MD and docking topologies. .mol2 files with partial charges can be obtained from ORCA calculations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\" # Name of the ligand to be docked\n",
    "flex_name = \"blind\" # Name of the pocket for the flex docking. 'blind' - blind docking and etc.\n",
    "\n",
    "HOME = \"\" # Full path to working directory\n",
    "REPOSITORY = \"\" # Full path to the folder containing scripts\n",
    "PATH_TO_DOCKING = f\"{HOME}/{NAME}\"\n",
    "PATH_TO_MD = f\"{HOME}/{NAME}\"\n",
    "PATH_TO_MOL2 = f\"{HOME}/{NAME}\"\n",
    "SCRIPT_LIGAND = f\"{REPOSITORY}/prep_wat.py\"\n",
    "\n",
    "SCRIPT_PARAM_LIGAND = f\"{REPOSITORY}/prep_lig.py\"\n",
    "\n",
    "TARGET_PATH = PATH_TO_DOCKING\n",
    "\n",
    "PATH_ADFR = f\"XXX/ADFRsuite-1.0/bin\" # Path to the ADFRSuite/bin package\n",
    "PYTHONSH = f\"{PATH_ADFR}/pythonsh\" # Path to the ADFRSuite package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ligand_file = f\"{NAME}_wat_charged.pdbqt\" # Final name of the ligand .pdbqt file to be generated\n",
    "receptor_file_pdb = \"receptor.pdb\" # Name of the receptor (protein) .pdb file\n",
    "\n",
    "receptor_name = receptor_file_pdb.split('.')[0]\n",
    "receptor_file = receptor_name+'.pdbqt' # Receptor .pdbqt file\n",
    "\n",
    "grid_name = f\"{flex_name}_site\"\n",
    "center_file = f\"{flex_name}_center.xyz\" #.xyz file containing the coordinates for the center of the search space\n",
    "\n",
    "# dict of flexible receptor residues used for flexible docking in format \"ARG114_ARG117_...\"\n",
    "residues_dict = { #\n",
    "    'noflex':\"\",\n",
    "    'site_name':\"ARG114_ARG117_ASP183_ASP187_ARG186_VAL116_LEU115\"\n",
    "}\n",
    "if flex_name in [\"\"]: # list of sites where flexible docking will be used\n",
    "    flex_residues = residues_dict[flex_name]\n",
    "else:\n",
    "    flex_residues = residues_dict['noflex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation and docking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy all required files from a special directory.\n",
    "\n",
    "The template directory contains all scripts necessary for docking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_PATH = f\"\"\n",
    "if not os.path.exists(TEMPLATE_PATH):\n",
    "        print(f\"Template directory does not exist.\")\n",
    "else:\n",
    "    os.system(f\"cp -r {TEMPLATE_PATH}/* {TARGET_PATH}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run parametrization of ligands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(PATH_TO_MOL2)\n",
    "%run  {SCRIPT_PARAM_LIGAND} {NAME}.mol2 {PATH_TO_DOCKING} {PATH_TO_MD} {SCRIPT_LIGAND} {PATH_ADFR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you already should have in target folder:\n",
    "1. Ligand file\n",
    "2. Receptor file (pdb)\n",
    "3. XYZ of the center of the docking box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare receptor both normal and for flexible.\n",
    "\n",
    "Check if your receptor is protonated. If not, you can use H++ server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! {PATH_ADFR}/prepare_receptor -r {receptor_file_pdb} -o {receptor_file} -v -A checkhydrogens\n",
    "if (flex_residues != \"\"):\n",
    "    ! {PYTHONSH} prepare_flexreceptor.py -r {receptor_file} -s {flex_residues} -v\n",
    "    ! mv {receptor_name}_flex.pdbqt {flex_name}.pdbqt\n",
    "    rigid_receptor_name = f\"{receptor_file.split('.pdbqt')[0]}_rigid.pdbqt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare grid file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 100 # Size of the docking box in Autodock units (default unit is 0.375 A)\n",
    "os.chdir(PATH_TO_DOCKING)\n",
    "# Optional: delete all files in the docking folder before running it again\n",
    "clear_grid = False\n",
    "if clear_grid:\n",
    "    ! rm -rf {grid_name}*/*run*\n",
    "    ! rm -rf {grid_name}*/*entity*\n",
    "    ! rm -rf {grid_name}*/cluster*\n",
    "    ! rm -rf {grid_name}*/*xml\n",
    "    ! rm -rf {grid_name}*/*dlg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run the Docking.\n",
    "\n",
    "Simply copy printed commands and put them in the terminal in the main directory for docking of your ligand\n",
    "\n",
    "Be careful with warnings about the number of evaluations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NRUNS = 2000 # Number of docking runs 1-8192\n",
    "HEUR = 20_000_000 # Number of evaluations\n",
    "\n",
    "if flex_residues != \"\":\n",
    "    print(f\"python3 gen_grids.py {PYTHONSH} {center_file} {rigid_receptor_name} {ligand_file} {SIZE} {grid_name}\")\n",
    "    print(f\"cp {flex_name}.pdbqt {grid_name}1/\")\n",
    "    if(HEUR > 0):\n",
    "        print(f\"python3 run_adgpu_flex.py {rigid_receptor_name} {ligand_file} {NRUNS} 1 {flex_name}.pdbqt {grid_name} {HEUR}\")\n",
    "    else:\n",
    "        print(f\"python3 run_adgpu_flex.py {rigid_receptor_name} {ligand_file} {NRUNS} 1 {flex_name}.pdbqt {grid_name}\")\n",
    "else:\n",
    "    print(f\"python3 gen_grids.py {PYTHONSH} {center_file} {receptor_file} {ligand_file} {SIZE} {grid_name}\")\n",
    "    if HEUR >0:\n",
    "        print(f\"python3 run_adgpu.py {receptor_file} {ligand_file} {NRUNS} 1  {grid_name} {HEUR}\")\n",
    "    else:\n",
    "        print(f\"python3 run_adgpu.py {receptor_file} {ligand_file} {NRUNS} 1  {grid_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse results of docking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname=NAME\n",
    "FOLDNAME = NAME\n",
    "\n",
    "iffilter = True\n",
    "n_filter = 7 # Threshold of pose population to be filtered\n",
    "centers = glob.glob(f\"{TARGET_PATH}/{grid_name}*\")\n",
    "i=0\n",
    "print(centers)\n",
    "\n",
    "\n",
    "k=0\n",
    "fig = plt.figure(dpi=100)\n",
    "fig_full = plt.figure(dpi=100)\n",
    "pymol_load = [f'cd {grid_name}{i+1}; disable all; ' for i in range(Tot)]\n",
    "for cent in centers:\n",
    "\tos.chdir(f\"{TARGET_PATH}/{grid_name}{i+1}\")\n",
    "\tenergy = subprocess.getoutput(\"awk '/RANKING/ {if ($1==1 && $2==1) print $4;}' *.dlg\")\n",
    "\truns = glob.glob(f\"{os.getcwd()}/*_run*\")\n",
    "\tclusters = subprocess.getoutput(\"xmllint --xpath '//result/clustering_histogram/cluster' *.xml\")\n",
    "\t# print(clusters)\n",
    "\tclusters = clusters.split(\"\\n\")\n",
    "\tprint(clusters)\n",
    "\tcluster = np.empty(len(clusters),dtype = int)\n",
    "\trun_energy = np.empty(len(clusters),dtype = float)\n",
    "\trun = np.empty(len(clusters),dtype = int)\n",
    "\tnclust = np.empty(len(clusters),dtype = int)\n",
    "\tclustfile = np.empty(len(clusters),dtype = object)\n",
    "\tfor idx, cl in enumerate(clusters):\n",
    "\t\tcl = cl.split()\n",
    "\t\tcluster[idx] = cl[1].split(\"=\")[1].replace('\"','')\n",
    "\t\trun_energy[idx] = cl[2].split(\"=\")[1].replace('\"','')\n",
    "\t\trun[idx] = cl[3].split(\"=\")[1].replace('\"','')\n",
    "\t\tnclust[idx] = cl[5].split(\"=\")[1].replace(\"/>\",'').replace('\"','')\n",
    "\t\tclustfile[idx] = f\"cluster{cluster[idx]}_{run_energy[idx]}_p{nclust[idx]}.pdbqt\"\n",
    "\tclust_data = pd.DataFrame(data={'cluster':cluster,'energy':run_energy, 'nrun':run, 'n in cluster':nclust, 'clusterfile':clustfile})\n",
    "\t# clust_data=clust_data.astype(float)\n",
    "\tclust_data = clust_data.sort_values(by=['n in cluster'], ascending=False)\n",
    "\tif iffilter:\n",
    "\t\tclust_data_filter=clust_data.query(f'`n in cluster` >={n_filter}')\n",
    "\t\n",
    "\tax = fig_full.add_subplot(1,1,0)\n",
    "\tclust_data.plot.bar(x='cluster', y='n in cluster', ax=ax, legend=False)\n",
    "\tax.axvspan(0, len(clust_data_filter), color='orange', alpha=0.4,\n",
    "\t label = f\"{round(clust_data_filter['n in cluster'].sum()/clust_data['n in cluster'].sum()*100)} % Filtered for n > {n_filter}\")\n",
    "\tplt.legend()\n",
    "\trects = ax.patches\n",
    "\tlabels = clust_data['energy']\n",
    "\tfor rect, label in zip(rects, labels):\n",
    "\t\theight = rect.get_height()\n",
    "\t\t# ax.text(rect.get_x() + rect.get_width() / 2, height+0.01, label, ha='center', va='bottom')\n",
    "\tplt.title(f\"{dataname}_grid{i+1}\")\n",
    "\n",
    "\tax2 = fig.add_subplot(1,1,0)\n",
    "\tclust_data_filter.plot.bar(x='cluster', y='n in cluster', ax=ax2, legend=False)\n",
    "\t\n",
    "\trects = ax2.patches\n",
    "\tlabels = clust_data_filter['energy']\n",
    "\tfor rect, label in zip(rects, labels):\n",
    "\t\theight = rect.get_height()\n",
    "\t\t# ax2.text(rect.get_x() + rect.get_width() / 2, height+0.01, label, ha='center', va='bottom')\n",
    "\t\n",
    "\tplt.title(f\"{dataname}_grid{i+1}\")\n",
    "\tfor file in clust_data_filter['clusterfile']:\n",
    "\t\tpymol_load[i]+=f\"load {file}; \"\n",
    "\ti+=1\n",
    "\tprint(clust_data_filter[\"n in cluster\"].sum())\n",
    "fs=16\n",
    "plt.xlabel(\"Cluster\", fontsize=fs)\n",
    "plt.ylabel(\"Population\", fontsize=fs)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "name_pymol = f\"{flex_name}_{n_filter}_\"\n",
    "for idx,s in enumerate(pymol_load):\n",
    "\tpymol_load[idx]+=f\" cd ..; group {name_pymol}{idx+1}, enabled\"\n",
    "print(len(clust_data_filter))\n",
    "print(\"\\n\".join(pymol_load))\n",
    "print(\"; \".join(pymol_load))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save chosen clusters as pdb files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_folder = f\"clusters_{n_filter}\"\n",
    "os.chdir(f\"{TARGET_PATH}/{grid_name}1\")\n",
    "if not(os.path.exists(clusters_folder) and os.path.isdir(clusters_folder)):\n",
    "    os.makedirs(clusters_folder)\n",
    "for file in clust_data_filter['clusterfile']:\n",
    "    # os.system(f\"cp {file} {clusters_folder}/\")\n",
    "    os.system(f\"obabel -ipdbqt {file} -opdb > {clusters_folder}/{file.split('.pdbqt')[0]}.pdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_PATH = f\"{TARGET_PATH}/{grid_name}1/{clusters_folder}/\"\n",
    "N_INIT = 150\n",
    "\n",
    "\n",
    "num = len(glob.glob(CLUSTER_PATH + \"*.pdb\"))\n",
    "centers = np.empty([num,3],dtype=float)\n",
    "population = np.empty([num],dtype=float)\n",
    "# out_centers = np.array([\"0\"]*(num), dtype = object)\n",
    "# out_clust = np.array([\"0\"]*(CLUSTER_NUM), dtype = object)\n",
    "i=0\n",
    "for file in glob.glob(CLUSTER_PATH + \"*.pdb\"):\n",
    "    dock = mda.Universe(file)\n",
    "    lig = dock.select_atoms(\"all\")\n",
    "    licent = str(lig.center_of_geometry()).replace('[','').replace(']','')\n",
    "    licent = licent.encode()\n",
    "    licent = licent.decode()\n",
    "    licent = licent.split()\n",
    "    licent =np.array(licent,dtype='float')\n",
    "    centers[i,:] = licent\n",
    "    population[i] = int(file.split('.pdb')[0].split('_p')[1])\n",
    "    i+=1\n",
    "print(CLUSTER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "\n",
    "sil_score = []\n",
    "dbs_score = []\n",
    "chs_score = []\n",
    "gap_score = []\n",
    "distorsions = []\n",
    "if len(centers) > 40:\n",
    "    SK = range(2,40)\n",
    "else:\n",
    "    SK = range(2,len(centers)-2)\n",
    "rr = random.randrange(1,10000)\n",
    "for i in SK:\n",
    "    kmeans= KMeans(n_clusters=i,n_init=N_INIT, random_state=rr).fit(centers, sample_weight=population)\n",
    "    labels= kmeans.labels_\n",
    "    distorsions.append(kmeans.inertia_)\n",
    "    sil = silhouette_score(centers,labels,metric=\"euclidean\", random_state=rr)\n",
    "    sil_score.append(sil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.matlib\n",
    "from kneed import KneeLocator\n",
    "\n",
    "def sec_der(wcss):\n",
    "    second_derivative = np.diff(wcss, 2)\n",
    "    elbow_point = np.argmax(np.abs(second_derivative)) + 1  # +1 because np.diff reduces the length by 1\n",
    "    return elbow_point\n",
    "def elb_kneed(wcss):\n",
    "    K = range(2,len(wcss)+2)\n",
    "    kneedle = KneeLocator(K, wcss, curve='convex', direction='decreasing', S=1)\n",
    "    elbow_point = kneedle.elbow\n",
    "    return elbow_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "fig = plt.figure(dpi=300)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(SK, distorsions)\n",
    "\n",
    "elbow_point = elb_kneed(distorsions) + 1  # +1 because index starts from 0\n",
    "\n",
    "print(f'Optimal number of clusters: {elbow_point}')\n",
    "plt.axvline(x=elbow_point, linestyle='--', color='red', label = f\"Elbow at {elbow_point}\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Elbow curve')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sil_centers = pd.DataFrame({'Clusters' : SK, 'Sil Score' : sil_score})\n",
    "sns.lineplot(x = 'Clusters', y = 'Sil Score', data = sil_centers, marker=\"+\")\n",
    "plt.title('Sillhoutte')\n",
    "sil_max = np.argmax(np.abs(sil_score)) + 2\n",
    "print(sil_score[sil_max])\n",
    "plt.axvline(x=elbow_point, linestyle='--', color='red', label = f\"Elbow at {elbow_point}\")\n",
    "plt.axvline(x=sil_max, linestyle='--', color='purple', label = f\"Max at {sil_max}\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f\"{FOLDNAME}/{grid_name}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "max_d = 65  # This is the distance threshold\n",
    "Z = linkage(centers, method='ward', metric='euclidean')\n",
    "clusters_cut = fcluster(Z, max_d, criterion='distance')\n",
    "plt.figure(dpi=300)\n",
    "dendrogram(Z)\n",
    "plt.axhline(y=max_d,linestyle='--', color='red', label = f\"Cutoff {max_d}, {max(clusters_cut)} clusters\")\n",
    "plt.title(f\"{FOLDNAME}/{grid_name} Dendrogram\")\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Distance')\n",
    "plt.legend()\n",
    "print(max(clusters_cut))\n",
    "# Z_cut = linkage(clusters_cut, method='ward')\n",
    "# dendrogram(Z_cut)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throw a d20 dice and choose a number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLUSTERS = 12\n",
    "kmeans = KMeans(n_clusters=NUM_CLUSTERS, n_init=N_INIT).fit(centers, sample_weight = population)\n",
    "labels = kmeans.predict(centers)\n",
    "centroids = kmeans.cluster_centers_\n",
    "out_centers = np.array([\"0\"]*(num), dtype = object)\n",
    "out_clust = np.array([\"0\"]*(NUM_CLUSTERS*3), dtype = object)\n",
    "weights = np.zeros([num],dtype=float)\n",
    "\n",
    "for j,l in enumerate(labels):\n",
    "    weights[l] += population[j]\n",
    "i=0\n",
    "\n",
    "combined = list(zip(centroids, weights))\n",
    "# Sort based on the weights\n",
    "sorted_combined = sorted(combined, key=lambda x: x[1], reverse=True)\n",
    "# Unzip the sorted arrays\n",
    "sorted_centroids, sorted_weights = zip(*sorted_combined)\n",
    "\n",
    "for clust in sorted_centroids:\n",
    "    cen = str(clust).replace('[','').replace(']','')\n",
    "    cen = \"F    \"+ cen\n",
    "    out_clust[i] = f\"1\"\n",
    "    out_clust[i+1] = f\"KM{i//3}_{NAME}_p{round(sorted_weights[i//3])}\"\n",
    "    out_clust[i+2] = cen\n",
    "    i+=3\n",
    "\n",
    "\n",
    "out_centers = np.insert(out_centers, 0,f\"Coordinates of DiffDock pockets for {NAME}\")\n",
    "# out_clust = np.insert(out_clust, 0,f\"Clusterized {CLUSTER_NUM} pockets for {NAME}\")\n",
    "np.savetxt(CLUSTER_PATH + f'{NAME}_centers.xyz',out_centers,fmt=\"%s\", encoding = 'latin1')\n",
    "np.savetxt(CLUSTER_PATH + f'{NAME}_clusters_{NUM_CLUSTERS}.xyz',out_clust,fmt=\"%s\", encoding = 'latin1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export results to PyMol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelClust(selname, divider):\n",
    "    divider = str(divider)\n",
    "    seleobj = cmd.get_object_list(selname)\n",
    "    for obj in seleobj:\n",
    "        # print(obj, divider)\n",
    "        name = f\"{obj.split(divider)[-1]} \"\n",
    "        if divider[-1] == 'p': # for population to easy\n",
    "            cmd.label(obj,f'\"p{name}\"')\n",
    "        else:\n",
    "            cmd.label(obj,f'\"{name}\"')\n",
    "            \n",
    "def renameObj_cluster(nameSelection = \"pk1\", spinlabel=\"C34R1\"):\n",
    "    seleobjs = cmd.get_object_list(nameSelection)\n",
    "    for obj in seleobjs:\n",
    "        labelobj = cmd.get_object_list(spinlabel)\n",
    "        labelname = \"\"\n",
    "        statenum = cmd.count_states(spinlabel)\n",
    "        dist=np.zeros(statenum)\n",
    "        for i in range(statenum):\n",
    "                dist[i]+=(cmd.get_distance(atom1=f\"{obj}\", atom2=f\"{spinlabel} and name O1\", state = i))\n",
    "        avdist = np.mean(dist)\n",
    "        disp = np.std(dist)\n",
    "        # print(\"Average distance is \", avdist)\n",
    "        # print(\"Dispersion is \", disp)\n",
    "        if(obj[-1] !='A'):\n",
    "            cmd.set_name(obj, f\"{obj}_{round(avdist)}A\")\n",
    "cmd.extend(\"renameObj_cluster\", renameObj_cluster)\n",
    "\n",
    "def getCluster_params(selname, divider):\n",
    "    data = []\n",
    "    divider = str(divider)\n",
    "    seleobj = cmd.get_object_list(selname)\n",
    "    for obj in seleobj:\n",
    "        print(obj, divider)\n",
    "        name = f\"{obj.split(divider)[-1]} \"\n",
    "        if divider[-1] == 'p': # for population to easy\n",
    "            name = f\"p{name}\"\n",
    "        clust_num = obj.split('_')[0].split('KM')[-1]\n",
    "        pop = int(name.split('_')[0][1:])\n",
    "        dist = int(name.split('_')[1][:-2])\n",
    "        data.append({'Cluster Population': pop, 'Average Distance (A)': dist})\n",
    "    df = pd.DataFrame(data)\n",
    "    # Rename the index\n",
    "    df.index.name = \"Cluster Number\"\n",
    "    df.index +=1\n",
    "    df = df.T\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymol_name = f\"{NAME}_docking.pse\"\n",
    "os.chdir(PATH_TO_DOCKING)\n",
    "if not os.path.isfile(pymol_name):\n",
    "    pymol_template = \"apo_template.pse\"\n",
    "    cmd.load(pymol_template)\n",
    "    cmd.load(CLUSTER_PATH + f'{NAME}_clusters.xyz')\n",
    "    cmd.split_states(f\"{NAME}_clusters\")\n",
    "    cmd.delete(f\"{NAME}_clusters\")\n",
    "    cmd.group(f\"{NAME}_clusters\", \"KM*\")\n",
    "    for file in clust_data_filter['clusterfile']:\n",
    "        cmd.load(f\"{TARGET_PATH}/{grid_name}1/\" + file)\n",
    "    cmd.remove(\"name WAT\")\n",
    "    cmd.group(\"poses\", f\"cluster*_*\")\n",
    "    renameObj_cluster(\"KM*\")\n",
    "    labelClust(\"KM*\", \"_p\")\n",
    "    table = getCluster_params(\"KM*\", \"_p\")\n",
    "\n",
    "    cmd.zoom(f\"receptor\")\n",
    "\n",
    "    cmd.save(pymol_name)\n",
    "else:\n",
    "    cmd.load(pymol_name)\n",
    "    table = getCluster_params(\"KM*\", \"_p\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show Dataframe with information about clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"renameObj_cluster KM*\")\n",
    "print(f\"labelClust KM*, _p\")\n",
    "# if flex_residues != \"\":\n",
    "table\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio_compute",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
